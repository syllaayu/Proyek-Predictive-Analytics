# -*- coding: utf-8 -*-
"""ML_PROYEK1_SYLLA_REV.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ywOzk6VtAy5GbSZVk6yD3uQfT5gJd93X

# Analisis Prediktif: Prediksi Data Churn Pelanggan Telekomunikasi
---
Oleh : Sylla Ayu Kusumahati
Proyek Submission 1 - Machine Learning Terapan Dicoding

## Pendahuluan
Pada proyek ini, topik yang dibahas adalah mengenai telekomunikasi yang dibuat untuk memprediksi data churn pelanggan telekomunikasi. Proyek ini dibuat untuk proyek Submission 1 - Machine Learning Terapan Dicoding. Untuk memudahkan navigasi di halaman, silahkan gunakan menu Table of Contents di kiri atas halaman.

# Pertama, import library yang dibutuhkan
"""

# Commented out IPython magic to ensure Python compatibility.
# Untuk pengolahan data
import pandas as pd
import numpy as np
import scipy.stats as stats
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

# Untuk visualisasi data
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import missingno as msno

# Untuk pembuatan model
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import GridSearchCV

# Untuk evaluasi model
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import mean_squared_error

"""# Kedua, Mempersiapkan Dataset

## 2.1 Menyiapkan kredensial akun Kaggle
"""

# install paket kaggle
!pip install -q kaggle

# Upload file kaggle.json, didapat dengan cara:
# Buka pengaturan akun kaggle.com, lalu Create New API Token
from google.colab import files
files.upload()

# Membuat folder .kaggle di dalam folder root
!rm -rf ~/.kaggle && mkdir ~/.kaggle/

# Menyalin berkas kaggle.json pada direktori aktif saat ini ke folder .kaggle
!mv kaggle.json ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json

"""## 2.2 Mengunduh dan Menyiapkan Dataset"""

# download datasets kaggle menggunakan API command
!kaggle datasets download -d blastchar/telco-customer-churn

# Mengekstrak berkas zip ke direktori aktif saat ini
!unzip /content/telco-customer-churn.zip

"""# Ketiga, Pemahaman Data (*Data Understanding*)

## 3.1 Load data pada sebuah Dataframe menggunakan pandas
"""

# load the datasets
data = pd.read_csv('/content/WA_Fn-UseC_-Telco-Customer-Churn.csv')
data

"""## 3.2 Informasi mengenai kolom pada dataset"""

data.info()

data.describe()

data.isnull().sum()

"""## 3.3 Visualisasi Data"""

#Memvisualisasikan Presentasi Churn
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.axis('equal')
labels = ['No', 'Yes']
churn = data.Churn.value_counts()
ax.pie(churn, labels=labels, autopct='%.0f%%')
plt.show()

# Plotting dengan fitur target
sns.countplot(data=data, x='Churn')
plt.title('Count of Churn')
plt.show()

"""### 3.3.1 Visualisasi data yang kosong"""

# Memvisualisasi data yang kosong
sorted_null = msno.nullity_sort(data, sort='descending') 
figures = msno.matrix(sorted_null, color=(1, 0.43, 0.43))

"""### 3.3.2 Membagi Dataset menjadi Fitur numerik dan fitur kategori"""

# Total charges ada di objek dtype jadi ubah menjadi fitur Numerik 
data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')

# numerical feature
numerical_feature = {feature for feature in data.columns if data[feature].dtypes != 'O'}
print(f'Count of Numerical feature: {len(numerical_feature)}')
print(f'Numerical feature are:\n {numerical_feature}')

# Categorical feature
categorical_feature = {feature for feature in data.columns if data[feature].dtypes == 'O'}
print(f'Count of Categorical feature: {len(categorical_feature)}')
print(f'Categorical feature are:\n {categorical_feature}')

# Plotting fitur numerik dengan distribusi probabilitas dan memeriksa outlier
for feature in numerical_feature:
    if feature != 'SeniorCitizen':
        plt.figure(figsize=(15,7))
    
        plt.subplot(1, 3, 1)
        sns.histplot(data=data, x=feature, bins=30, kde=True)
        plt.title('Histogram')
    
        plt.subplot(1, 3, 2)
        stats.probplot(data[feature], dist="norm", plot=plt)
        plt.ylabel('RM quantiles')
    
        plt.subplot(1, 3, 3)
        sns.boxplot(x=data[feature])
        plt.title('Boxplot')
    
plt.show()

"""### 3.3.3 Distribusi data pada kolom dengan fitur numerik ('MonthlyCharges', 'SeniorCitizen', 'tenure')"""

# mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(data,vars = ['TotalCharges','MonthlyCharges','tenure'], hue="Churn")

"""### 3.3.4 Distribusi kelas pada kolom dengan fitur kategori"""

#Exploratory Data Analysis (EDA) Variabel Katagorik
for i, feature in enumerate(categorical_feature):
    if feature != 'Churn':
        if feature != 'customerID':
            plt.figure(i)
            plt.figure(figsize=(12,6))
            sns.countplot(data=data, x=feature, hue='Churn')
plt.show()

"""### 3.3.5 Korelasi data antar kolom dengan fitur numerik"""

plt.figure(figsize=(10, 8))
correlation_matrix = data.corr().round(2)
# annot = True to print the values inside the square
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""# Keempat, Persiapan Data (Data Preparation)

## 4.1 Mengatasi masalah data yang kosong dengan nilai rata-rata kolom (mean substitution)
"""

# Mengecek kembali nilai yang kosong pada dataset
data.isnull().sum()

# ganti nilai NaN dengan nilai rata-rata
data.TotalCharges = data.TotalCharges.fillna(data.TotalCharges.mean())

# Mengecek total baris dan kolom dari dataset
data.shape

"""## 4.2 Encoding Fitur Kategori"""

#Encoding Data
encoder = LabelEncoder()
for feature in categorical_feature:
    data[feature] = encoder.fit_transform(data[feature])

# Menghapus kolom customerID
data.drop(columns=['customerID'], inplace=True)

"""## 4.3 Melakukan pembagian data pada dataset dengan train_test_split"""

# splitting dataset
X = data.drop(columns='Churn')
y = data['Churn']

# splitting for train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Mengecek jumlah baris pada data latih dan data 
print('Jumlah baris dan kolom X_train adalah:', X_train.shape, ', sedangkan jumlah baris dan kolom y_train adalah:', y_train.shape)
print('Presentase Churn di data training adalah:')
print(y_train.value_counts(normalize=True))
print('Jumlah baris dan kolom X_test adalah:', X_test.shape, ', sedangkan jumlah baris dan kolom y_test adalah:', y_test.shape)
print('Presentase Churn di data Testing adalah:')
print(y_test.value_counts(normalize=True))

"""## 4.3 Standarisasi nilai data pada fitur numerik dengan StandardScaler"""

# menggunakan metode StandardScaler 
numerical_features = ['TotalCharges', 'MonthlyCharges', 'tenure', 'SeniorCitizen']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

# Deskripsi 
X_train[numerical_features].describe().round(4)

# Mengecek jumlah baris pada data latih dan data 
print(X_train.shape)
print(X_test.shape)

"""# Kelima, Pembuatan Model

## 5.1 Melatih dengan beberapa model yang terbaik untuk dijadikan Model Baseline
"""

# Siapkan daraframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'], 
                      columns=['KNN', 'RN', 'Boosting'])

# Melatih data dengan KNN
knn = KNeighborsClassifier(n_neighbors=10)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_train)

# Melatih data dengan Random Forests
rf = RandomForestClassifier(n_estimators=10, max_depth=16, random_state=15, n_jobs=-1)
rf.fit(X_train, y_train)
 
models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=rf.predict(X_train), y_true=y_train)

# Melatih data dengan AdaBoost
boosting = AdaBoostClassifier(n_estimators=10, learning_rate=0.01, random_state=15)                             
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

# Proses scaling terhadap data uji
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

# evaluasi ketiga model kita dengan metrik MSE
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN', 'RF', 'Boosting'])
model_dict = {'KNN': knn, 'RF': rf, 'Boosting': boosting}
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3 
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3
 
mse

# Plot metrik dengan bar chart
fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

# Prediksi menggunakan beberapa harga dari data test
prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)
 
pd.DataFrame(pred_dict)

"""## 5.2 Model Baseline dengan Algoritma K-Nearest Neighbors"""

# Pembuatan model baseline
baseline_model = KNeighborsClassifier()
baseline_model.fit(X_train, y_train)

# Pengujian model terhadap data test
y_pred = baseline_model.predict(X_test)

# Laporan hasil klasifikasi model baseline
baseline_report = classification_report(y_test, y_pred, output_dict=True, target_names=['Not Churn','Churn'])
pd.DataFrame(baseline_report).transpose()

# Menyimpan hasil prediksi untuk confussion matrix
baseline_cf = confusion_matrix(y_test, y_pred)

"""## Pengembangan Model K-Nearest Neighbors dengan Hyper Parameter Tuning menggunakan GridSearchCV"""

# Hyperparameter yang akan di tuning
param_grid = {'n_neighbors': [1, 2],
              'p': [1, 2],
              'weights': ["uniform","distance"],
              'algorithm':["ball_tree", "kd_tree", "brute"],
              }

# Pencarian parameter terbaik dengan GridSearchCV
clf = GridSearchCV(baseline_model, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)

# Hasil hyperparameter tuning
best_clf = clf.fit(X_train,y_train)

# Hasil hyperparameter tuning
best_clf.best_estimator_

# Hasil hyperparameter tuning
 best_clf.best_score_

# Penerapan hyperparameter pada model baseline
model = KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,
                     weights='uniform')
model.fit(X_train, y_train)

# Pengujian model terhadap data test
y_pred = model.predict(X_test)

# Laporan hasil klasifikasi model baseline
improvement_report = classification_report(y_test, y_pred, output_dict=True, target_names=['Not Churn','Churn'])
pd.DataFrame(improvement_report).transpose()

# Menyimpan hasil prediksi untuk confussion matrix
improvement_cf = confusion_matrix(y_test, y_pred)

"""# Keenam, Evaluasi Model

## 6.1 Perbandingan metriks antara model baseline dengan model yang dikembangkan
"""

# Memasukkan hasil laporan klasifikasi model pada dataframe
metrics = pd.DataFrame({'accuracy' : [baseline_report['accuracy'], improvement_report['accuracy']],
                        'f1-score_0' : [baseline_report['Not Churn']['f1-score'],improvement_report['Not Churn']['f1-score']],
                        'precision_0' : [baseline_report['Not Churn']['precision'],improvement_report['Not Churn']['precision']],
                        'recall_0' : [baseline_report['Not Churn']['recall'],improvement_report['Not Churn']['recall']],
                        'f1-score_1' : [baseline_report['Churn']['f1-score'],improvement_report['Churn']['f1-score']],
                        'precision_1' : [baseline_report['Churn']['precision'],improvement_report['Churn']['precision']],
                        'recall_1' : [baseline_report['Churn']['recall'],improvement_report['Churn']['recall']]},
                        index=['Model Baseline','Model yang Dikembangkan'])
multiheader = [('','accuracy'),
               ('Not Churn', 'f1-score'),
               ('Not Churn', 'precision'),
               ('Not Churn', 'recall'),
               ('Churn', 'f1-score'),
               ('Churn', 'precision'),
               ('Churn', 'recall')]
metrics.columns = pd.MultiIndex.from_tuples(multiheader)
# Menampilkan dataframe
metrics

"""## 6.2 Confussion Matrix"""

# Visualisasi hasil prediksi model baseline
figures = pd.DataFrame(baseline_cf, ('No churn', 'Churn'), ('No churn', 'Churn'))
plt.figure()
heatmap = sns.heatmap(figures, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)
plt.title('Confusion Matrix untuk Model Baseline)\n', fontsize=18, color='darkblue')
plt.ylabel('True label', fontsize=14)
plt.xlabel('Predicted label', fontsize=14)
plt.show()

# Visualisasi hasil prediksi model yang dikembangkan
figures = pd.DataFrame(improvement_cf, ('No churn', 'Churn'), ('No churn', 'Churn'))
plt.figure()
heatmap = sns.heatmap(figures, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)
plt.title('Confusion Matrix untuk Model yang dikembangkan)\n', fontsize=18, color='darkblue')
plt.ylabel('True label', fontsize=14)
plt.xlabel('Predicted label', fontsize=14)
plt.show()

"""# Penutupan

Akhirnya kita telah sampai pada tahap akhir dalam memprediksi churn pelanggan telekomunikasi ini. Pemilihan algoritma dari perbandingan diatas jatuh kepada K-Nearest Neighbors. Karena dari hasil perbandingan K-Nearest Neighbors lah yang memiliki keseimbangan nilai error, ditunjukkan pada plot matrix. Setelah itu penerapan Hyperparameter pada model baseline menggunakan GridSearchCV. Dengan penerapan ini akurasi menjadi meningkat, walaupun pada precision, f1-score dan recall mengalami sedikit penurunan. Namun, akurasi sudah terlihat baik.

## Referensi :


*   Dokumentasi Scikit-learn : https://scikit-learn.org/stable/modules/classes.html
*   Dokumentasi Plotly : https://plotly.com/python/
*   Dokumentasi Hyperparameter : https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html
Lainnya :

    *   https://www.kaggle.com/ahalaa/churn-model-using-random-forest-vsm-and-ann#Applying-ML-Models
    *   https://www.kaggle.com/puisingwong/machine-learning-in-customer-churn-prediction
    *   https://www.kaggle.com/ozdemirh/customer-churn-prediction-with-knn-classifier#Standardization
"""